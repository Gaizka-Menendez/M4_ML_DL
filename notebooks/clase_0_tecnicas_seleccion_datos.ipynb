{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f965b64",
   "metadata": {},
   "source": [
    "<img src=\"../img/carlos_portrait.jpg\" width=150 align=\"right\">\n",
    "\n",
    "# 1.- Introducción al Machine Learning\n",
    "\n",
    "Autor: Carlos Moreno Morera\n",
    "\n",
    "Contacto: carmor06@ucm.es\n",
    "\n",
    "Última revisión por Sergio Benito Martín: 31/05/2025\n",
    "\n",
    "# 1.3 - Tecnicas de selección de datos\n",
    "\n",
    "En este Notebook vamos a implementar las ***4 técnicas de selección de datos***; es decir, de que manera se puede dividir el dataset inicial en conjuntos de datos de entrenamiento y test. Para ello utilizaremos la librería de ***Scikit-Learn***.\n",
    "\n",
    "Para evaluar los modelos obtenidos tras la aplicación de alguna de las técnicas de ML, es necesario disponer de un ***conjunto de datos*** (etiquetados o no) para ***generar el mejor modelo  posible y minimizar el error empírico***.\n",
    "\n",
    "Dado un conjunto de datos, podemos enumerar los siguientes ***métodos de selección de datos***:\n",
    "<span></span><br><br>\n",
    "    - **[Resustitución](#M0)**: Todos los datos disponibles se utilizan como datos de test y de entrenamiento.\n",
    "<span></span><br><br>\n",
    "    - **[Partición (Hold Out)](#M1)**: Divide los datos en dos subconjuntos: uno de entrenamiento y uno de test.\n",
    "<span></span><br><br>\n",
    "    - **[Validación cruzada (Cross Validation)](#M2)**: Divide los datos aleatoriamente en ‘N’ bloques. Cada bloque se utiliza como test para un sistema entrenado por el resto de bloques.\n",
    "<span></span><br><br>\n",
    "    - **[Exclusión individual (Leave One Out)](#M3)**: Este método utiliza cada dato individual como dato único de test de un sistema entrenado con todos los datos excepto el de test.\n",
    "\n",
    "## Ejemplos\n",
    "\n",
    "\n",
    "Para ver ejemplos de estas técnicas de evaluación supongamos el siguiente conjunto de datos donde:\n",
    "\n",
    "- ***(i)***: índice del conjunto de datos.\n",
    "- ***X<sub>1</sub> y X<sub>2</sub>***: Variables de entrada.\n",
    "- ***y***: Variable de salida.\n",
    "\n",
    "\n",
    "|(i)|X<sub>1</sub>|X<sub>2</sub>|y|\n",
    "|---|---|---|---|\n",
    "|0|0|1|1|\n",
    "|1|1|1|4|\n",
    "|2|1|2|6|\n",
    "|3|2|1|7|\n",
    "|4|2|2|9|\n",
    "|5|3|1|10|\n",
    "|6|3|2|12|\n",
    "|7|3|3|14|\n",
    "|8|1|3|8|\n",
    "|9|2|3|11|\n",
    "\n",
    "\n",
    "En este ejemplo vamos a tener ***10 elementos*** en nuestro conjundo de datos y los vamos a pasar a un ***array de numpy***:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cbc5ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [2, 1],\n",
       "       [2, 2],\n",
       "       [3, 1],\n",
       "       [3, 2],\n",
       "       [3, 3],\n",
       "       [1, 3],\n",
       "       [2, 3]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([[0,1],[1,1],[1,2],[2,1],[2,2],[3,1],[3,2],[3,3],[1,3],[2,3]])\n",
    "y = np.array([1,4,6,7,9,10,12,14,8,11])\n",
    "\n",
    "np.random.seed(42)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c9beb6c-b595-4a17-8283-e585cf87c1fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  4,  6,  7,  9, 10, 12, 14,  8, 11])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c4aeef",
   "metadata": {},
   "source": [
    "## <a name=\"M0\">1. Resustitución</a>\n",
    "\n",
    "Para el caso de la resustitución es muy sencilla; ***todos los datos del Dataset sirven para el Entrenamiento y el Test***. A modo didáctico realizamos la siguiente asignación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc461984",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X\n",
    "y_train = y\n",
    "\n",
    "# modelo Algoritmo_de_Aprendizaje.entrenar(X_train, y_train)\n",
    "\n",
    "X_test = X\n",
    "y_test = y\n",
    "\n",
    "# evaluacion = modelo.evaluar(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182761d2",
   "metadata": {},
   "source": [
    "## <a name=\"M1\">2. Hold Out</a>\n",
    "\n",
    "La técnica de evaluación ***Hold Out*** divide el Dataset en un ***conjunto de datos de entrenamiento*** y otro ***conjunto de datos de test***, seleccionados a priori de manera aleatoria.\n",
    "\n",
    "\n",
    "<img src=\"../img/tecnicas_seleccion/tsl_particion.png\" style=\"width: 500px;\"/>\n",
    "\n",
    "Implementémoslo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4747fd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def particion(X, y, porcentaje_test):\n",
    "    num_test = round(len(X)*porcentaje_test)\n",
    "    indices_test = np.random.choice(X.shape[0], num_test, replace=False) # replace sirve para indicar si se pueden coger los mismos indices\n",
    "    X_train = np.delete(X, indices_test, 0)\n",
    "    y_train = np.delete(y, indices_test, 0)\n",
    "\n",
    "    X_test = X[indices_test]\n",
    "    y_test = y[indices_test]\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "np.random.seed(42)\n",
    "X_train, y_train, X_test, y_test = particion(X, y, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4060ea88-c02c-4330-8285-2f2b9a8bc977",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 2],\n",
       "       [2, 1],\n",
       "       [2, 2],\n",
       "       [3, 1],\n",
       "       [3, 2],\n",
       "       [3, 3],\n",
       "       [2, 3]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe2089e4-2369-4813-ba20-c1cf1ce003da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  6,  7,  9, 10, 12, 14, 11])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9a9966",
   "metadata": {},
   "source": [
    "En Scikit utilizamos la función ***train_test_split(X,y,test_size)*** para que nos divida en dos conjuntos el Dataset, indicando como parámetro el porcentaje de datos de test que quermos obtener:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09864694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 3]\n",
      " [3 1]\n",
      " [2 1]\n",
      " [2 2]\n",
      " [3 3]\n",
      " [2 3]\n",
      " [3 2]\n",
      " [1 2]]\n",
      "[[0 1]\n",
      " [1 1]]\n",
      "[ 8 10  7  9 14 11 12  6]\n",
      "[1 4]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, y_train, X_test, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "print(X_train)\n",
    "print(y_train)\n",
    "print(X_test)\n",
    "print(y_test)\n",
    "\n",
    "# modelo Algoritmo_de_Aprendizaje.entrenar(X_train, y_train)\n",
    "\n",
    "# evaluacion = modelo.evaluar(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c97419",
   "metadata": {},
   "source": [
    "## <a name=\"M2\">3. Cross Validation</a>\n",
    "\n",
    "La técnica del ***Cross Validation, divide el Dataset en 'N' conjuntos*** (o Folds como Scikit lo llama). Para cada uno de los ***'N'*** casos se utiliza un conjunto como datos de test y el resto de conjuntos como datos de entrenamiento. Esta técnica tiene sentido aplicarla cuando se quiere evaluar el modelo generado ***'N'*** veces.\n",
    "\n",
    "\n",
    "<img src=\"../img/tecnicas_seleccion/tsl_cv.png\" style=\"width: 600px;\"/>\n",
    "\n",
    "Comencemos implementando la validación cruzada de K-iteraciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6be5ba88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices Train - Indices Test\n",
      "[0, 7, 2, 9, 4, 3, 6] - [8, 1, 5]\n",
      "[8, 1, 5, 9, 4, 3, 6] - [0, 7, 2]\n",
      "[8, 1, 5, 0, 7, 2, 6] - [9, 4, 3]\n",
      "[8, 1, 5, 0, 7, 2, 9, 4, 3] - [6]\n"
     ]
    }
   ],
   "source": [
    "def cv_k_iterations(X, y, k):\n",
    "    block_size = len(X)//k\n",
    "\n",
    "    if len(X) % k > 0:\n",
    "        block_size+=1\n",
    "\n",
    "    indices = list(np.random.choice(X.shape[0], len(X), replace=False))\n",
    "    test_indices = [indices[i*block_size:(i+1)*block_size] for i in range(k)]\n",
    "    train_indices = [(indices[:i*block_size] + indices[(i+1)*block_size:]) for i in range(k)]\n",
    "    return list(zip(train_indices, test_indices))\n",
    "\n",
    "print(\"Indices Train - Indices Test\")\n",
    "for train, test in cv_k_iterations(X, y, 4):\n",
    "    print(\"{} - {}\".format(train, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1efe8f4",
   "metadata": {},
   "source": [
    "A continuación, veamos cómo implementar la validación cruzada aleatoria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6be1b3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices Train - Indices Test\n",
      "[0, 2, 3, 4, 6, 7, 9] - [8, 1, 5]\n",
      "[2, 3, 4, 5, 6, 7, 9] - [0, 1, 8]\n",
      "[1, 3, 4, 5, 6, 7, 8] - [9, 2, 0]\n",
      "[0, 2, 3, 4, 5, 8, 9] - [1, 7, 6]\n"
     ]
    }
   ],
   "source": [
    "def cv_aleatoria(X, y, k, size):\n",
    "    indices = np.array(list(range(X.shape[0])))\n",
    "    test_indices = [list(np.random.choice(X.shape[0], size, replace=False)) for i in range(k)]\n",
    "    train_indices = [list(np.delete(indices, test_indices[i], 0)) for i in range(k)]\n",
    "    return list(zip(train_indices, test_indices))\n",
    "\n",
    "print(\"Indices Train - Indices Test\")\n",
    "for train, test in cv_aleatoria(X, y, 4, 3):\n",
    "    print(\"{} - {}\".format(train, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7c49c4",
   "metadata": {},
   "source": [
    "En Scikit utilizamos la clase ***KFold(n_splits)*** para dividir el Dataset en ***'N'*** (n_splits) conjuntos. En este caso no vamos a obtener unos arrays con los datos de entrenamiento y test; si no, los ***índices de los elementos del Dataset que en cada paso actuarán como entrenamiento y como test***:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b68117a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices Train - Indices Test\n",
      "[3 4 5 6 7 8 9] - [0 1 2]\n",
      "[0 1 2 6 7 8 9] - [3 4 5]\n",
      "[0 1 2 3 4 5 8 9] - [6 7]\n",
      "[0 1 2 3 4 5 6 7] - [8 9]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "k_fold = KFold(n_splits=4)\n",
    "print(\"Indices Train - Indices Test\")\n",
    "for train, test in k_fold.split(X,y):\n",
    "    print(\"{} - {}\".format(train, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f83021b9-6ab2-427c-bed0-0e22eb6f9b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train: [ 7  9 10 12 14  8 11]\n",
      "y_test: [1 4 6]\n",
      "y_train: [ 1  4  6 12 14  8 11]\n",
      "y_test: [ 7  9 10]\n",
      "y_train: [ 1  4  6  7  9 10  8 11]\n",
      "y_test: [12 14]\n",
      "y_train: [ 1  4  6  7  9 10 12 14]\n",
      "y_test: [ 8 11]\n"
     ]
    }
   ],
   "source": [
    "# Dividimos el dataset en 5 conjuntos de datos\n",
    "k_fold = KFold(n_splits=4)\n",
    "\n",
    "# Ejemplo de como accedemos a los elementos de la variable de salida y\n",
    "for train, test in k_fold.split(X, y):\n",
    "    print(\"y_train: {}\".format(y[train]))\n",
    "    # modelo = Algoritmo_de_Aprendizaje.entrenar(X[train], y[train])\n",
    "\n",
    "    print(\"y_test: {}\".format(y[test]))\n",
    "    # evaluar_modelo = modelo.evaluar(X[test], y[test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44be3bcd",
   "metadata": {},
   "source": [
    "## <a name=\"M3\">4. Leave One Out</a>\n",
    "\n",
    "La técnica del ***Leave One One*** es una técnica similar al Cross Validation, pero en este caso el Dataset se ***divide en tantos conjuntos como elementos tenga el Dataset***. Para cada uno de los ***'M'*** elemetos se utiliza un elemento como dato de test y el resto de elementos como datos de entrenamiento. Esta ***técnica es muy costosa de aplicar*** ya que se van a tener tantas iteracciones como elementos tenga el Dataset (***'M'*** veces). Puede tener sentido aplicar esta técnica cuando se tenga un Dataset pequeño y necesitemos evaluar muy a fondo el modelo.\n",
    "\n",
    "\n",
    "<img src=\"../img/tecnicas_seleccion/tsl_leave1out.png\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6c382b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices Train - Indices Test\n",
      "[1, 8, 5, 3, 4, 7, 9, 6, 2] - [0]\n",
      "[0, 8, 5, 3, 4, 7, 9, 6, 2] - [1]\n",
      "[0, 1, 5, 3, 4, 7, 9, 6, 2] - [8]\n",
      "[0, 1, 8, 3, 4, 7, 9, 6, 2] - [5]\n",
      "[0, 1, 8, 5, 4, 7, 9, 6, 2] - [3]\n",
      "[0, 1, 8, 5, 3, 7, 9, 6, 2] - [4]\n",
      "[0, 1, 8, 5, 3, 4, 9, 6, 2] - [7]\n",
      "[0, 1, 8, 5, 3, 4, 7, 6, 2] - [9]\n",
      "[0, 1, 8, 5, 3, 4, 7, 9, 2] - [6]\n",
      "[0, 1, 8, 5, 3, 4, 7, 9, 6] - [2]\n"
     ]
    }
   ],
   "source": [
    "def leave_one_out(X, y):\n",
    "    return cv_k_iterations(X, y, len(X))\n",
    "\n",
    "print(\"Indices Train - Indices Test\")\n",
    "for train, test in leave_one_out(X,y):\n",
    "    print(\"{} - {}\".format(train, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6364467",
   "metadata": {},
   "source": [
    "En Scikit utilizamos la clase ***LeaveOneOut()*** para dividir el Dataset en tantos conjuntos como elementos tenga. En este caso no vamos a obtener unos arrays con los datos de entrenamiento y test; si no, los ***índices de los elementos del Dataset que en cada paso actuarán como entrenamiento y como test***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07dcc364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices Train - Indices Test\n",
      "[1 2 3 4 5 6 7 8 9] - [0]\n",
      "[0 2 3 4 5 6 7 8 9] - [1]\n",
      "[0 1 3 4 5 6 7 8 9] - [2]\n",
      "[0 1 2 4 5 6 7 8 9] - [3]\n",
      "[0 1 2 3 5 6 7 8 9] - [4]\n",
      "[0 1 2 3 4 6 7 8 9] - [5]\n",
      "[0 1 2 3 4 5 7 8 9] - [6]\n",
      "[0 1 2 3 4 5 6 8 9] - [7]\n",
      "[0 1 2 3 4 5 6 7 9] - [8]\n",
      "[0 1 2 3 4 5 6 7 8] - [9]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "print(\"Indices Train - Indices Test\")\n",
    "for train, test in LeaveOneOut().split(X):\n",
    "    print(\"{} - {}\".format(train, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9177a0df-25e5-4e36-8f08-75bb467591e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-pontia-ml",
   "language": "python",
   "name": "env-pontia-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
